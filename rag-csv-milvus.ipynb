{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found .env: %s True\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "founddotenv = load_dotenv(find_dotenv(), override=True) \n",
    "print(\"Found .env: %s\", founddotenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "path = \"./pull_requests_summary.csv\"\n",
    "\n",
    "import csv\n",
    "csv.field_size_limit(10**6)\n",
    "\n",
    "loader = CSVLoader(file_path=path, encoding=\"utf-8\", csv_args={'delimiter': ','})\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "#embeddings = OpenAIEmbeddings()\n",
    "#embeddings = OpenAIEmbeddings(model= \"text-embedding-3-large\", dimensions=1536) #text-embedding-3-small\n",
    "embeddings = OpenAIEmbeddings(model= \"text-embedding-3-large\") #text-embedding-3-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_milvus import Milvus\n",
    "def send_chunks_to_Milvus_Db (subchunk) :   \n",
    "    vectorstore = Milvus.from_documents(  # or Zilliz.from_documents\n",
    "        documents=subchunk,\n",
    "        embedding=embeddings,\n",
    "        collection_name=\"milvus_csv\",\n",
    "        connection_args={\"uri\": \"./milvus_csv.db\"},\n",
    "        #drop_old=True,  # Drop the old Milvus collection if it exists\n",
    "    )\n",
    "    print(\"Added chunks to DB : \", len(subchunk))\n",
    "\n",
    "    #load the store\n",
    "    vectorstore = Milvus(\n",
    "        embeddings,\n",
    "        connection_args={\"uri\": \"./milvus_csv.db\"},\n",
    "        collection_name=\"milvus_csv\"\n",
    "    )\n",
    "    print(\"loaded mulvus\")\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks :  4281\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=25)\n",
    "chunks = text_splitter.split_documents(data)\n",
    "print(\"Total Chunks : \", len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added chunks to DB :  4526\n"
     ]
    }
   ],
   "source": [
    "vectorstore = send_chunks_to_Milvus_Db(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chunk Groups :  3\n"
     ]
    }
   ],
   "source": [
    "#how many chunks?\n",
    "count_max = 2000\n",
    "quotient = len(chunks) // count_max\n",
    "remainder = len(chunks) % count_max\n",
    "if remainder > 0:\n",
    "    total_chunks = quotient + 1\n",
    "else :\n",
    "    total_chunks = quotient\n",
    "print(\"Number of Chunk Groups : \", total_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk name :  chunk-0\n",
      "Chunk name :  chunk-1\n",
      "Chunk name :  chunk-2\n",
      "Chunk List :  3\n"
     ]
    }
   ],
   "source": [
    "chunk_list = []\n",
    "for i in range(total_chunks):\n",
    "    chunk_name = f\"chunk-{i}\"\n",
    "    chunk_list.append(chunk_name)\n",
    "    print(\"Chunk name : \", chunk_name)\n",
    "print(\"Chunk List : \", len(chunk_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_into_milvus(chunk_list):\n",
    "    remaining = len(chunks)\n",
    "    for name in chunk_list:\n",
    "        if remaining > count_max :\n",
    "            name = chunks[:count_max]\n",
    "            remaining = remaining - count_max\n",
    "            print(\"Chunk Size : \", len(name))\n",
    "            vectorstore = send_chunks_to_Milvus_Db(name)\n",
    "        else :\n",
    "            name = chunks[:remaining]\n",
    "            print(\"Last Chunk Size : \", len(name))\n",
    "            vectorstore = send_chunks_to_Milvus_Db(name)\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size :  2000\n",
      "Added chunks to DB :  2000\n",
      "loaded mulvus\n",
      "Chunk Size :  2000\n",
      "Added chunks to DB :  2000\n",
      "loaded mulvus\n",
      "Last Chunk Size :  281\n",
      "Added chunks to DB :  281\n",
      "loaded mulvus\n"
     ]
    }
   ],
   "source": [
    "vectorstore = insert_into_milvus(chunk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Human: You are an AI assistant, and provides answers to questions by using fact based and statistical information when possible.\n",
    "Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags.\n",
    "Your will be presented with a document containing 3 columns\n",
    "The first column is \"Commit ID\". This is the primary key and will be unique\n",
    "The Second column is \"Changes\"\n",
    "The Third column is \"Comments\"\n",
    "Each unique \"Commit ID\" will be a row containing \"Changes\" and \"Comments\"\n",
    "So, if there are 20 commit IDs, there would be 20 rows\n",
    "Look through the whole document before answering the question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "The response should be specific and use statistics or numbers when possible.\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=PROMPT_TEMPLATE, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 250})\n",
    "#retriever = vectorstore.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={'score_threshold': 0.5})\n",
    "#retriever = vectorstore.as_retriever(search_type=\"mmr\",search_kwargs={'k': 50, 'fetch_k': 100})\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 unique Commit IDs present in the document. Here are the Commit IDs:\n",
      "1. 97ac5a506b358d29c298aecadd41060d62cecc4b\n",
      "2. 949be2ac0e957cfbe981da242384424b4786067a\n",
      "3. 3ecedef3e81ac4104fe3f0a028aafad496ed6b42\n",
      "4. 0fa74824f9fefec08acfe117866dc587563730d5\n",
      "5. 39c8f648fdb08e8717237ae4ffca5b181cd3fd33\n",
      "6. c8ece09049aab49a3563e0270356ff252cab07ec\n",
      "7. 8a493a8f89f9c9d108922bd83af39f776ee6c76b\n",
      "8. 1463a176bf652172560c3893c84b61c86e1b47f5\n",
      "9. 26d2d44b12c28580549b6ade52bb6a4949cfe521\n",
      "10. 4acc32ac9bf2dde41083bac73dc15f89cc69345d\n"
     ]
    }
   ],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "query = \"How many unique Commit ID are present? Name all you find\"\n",
    "#query = \"Print all the unique commit ID\"\n",
    "#query = \"How many rows are present in the documents?\"\n",
    "#query = \"how many columns are present and which is the 2nd column?\"\n",
    "#query = \"How many unique Commit ID are present? Which are the 2 most similar commit IDs and why?\"\n",
    "res = rag_chain.invoke(query)\n",
    "print(res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
